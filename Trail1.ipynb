{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Govindkaranam/Virtual_CChartGpt/blob/main/Trail1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7j0TeE6dgo-"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/Projects/NLP/LLM_Project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wPxTIEBDLhgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install unstructured\n",
        "!pip install faiss-cpu\n",
        "!pip install faiss-gpu\n",
        "!pip install tiktoken\n",
        "!pip install openai\n",
        "!pip install sentence_transformers\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "imQTZb23eJ2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "id": "g7yplmqFl96d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pickle\n",
        "import faiss\n",
        "from langchain import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import VectorDBQAWithSourcesChain\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import CharacterTextSplitter, NLTKTextSplitter"
      ],
      "metadata": {
        "id": "cRtR0p6beP2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_file = open(\"/content/drive/MyDrive/Projects/NLP/LLM_Project/Scrap_data/keras.txt\", \"r\")\n",
        "  \n",
        "# reading the file\n",
        "data = my_file.read()\n",
        "# replacing end splitting the text \n",
        "# when newline ('\\n') is seen.\n",
        "data_into_list = data.split(\"\\n\")\n",
        "data_into_list.pop()\n",
        "print(data_into_list) \n",
        "my_file.close()"
      ],
      "metadata": {
        "id": "vYK3OM1WeWcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_into_list)"
      ],
      "metadata": {
        "id": "BzQeYCZgeWfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for url in data_into_list:\n",
        "  if url.endswith('.pdf'):\n",
        "    data_into_list.remove(url)\n",
        "  elif url.endswith('.py'):\n",
        "    data_into_list.remove(url)\n",
        "  else:\n",
        "    pass"
      ],
      "metadata": {
        "id": "W5acyxwVeWtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_into_list)"
      ],
      "metadata": {
        "id": "3c6aDNs9eWvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,url in enumerate(data_into_list):\n",
        "  try:\n",
        "    loader = UnstructuredURLLoader(urls=[url])\n",
        "    data = loader.load()      \n",
        "    dict_format={\"Source\":data[0].metadata[\"source\"],\n",
        "              \"Content\":data[0].page_content.replace(\"\\n\",\"\")}\n",
        "    with open(f'/content/drive/MyDrive/Projects/NLP/LLM_Project/Cleaned_data/Scarp_{i}.json', 'w') as file_handler:\n",
        "      json.dump(dict_format,file_handler,indent=1)\n",
        "      print(f'Scarp.json__{i}.--------> Completed')\n",
        "  except Exception as exc:\n",
        "    print('file not found')"
      ],
      "metadata": {
        "id": "bwwXd1JueWzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files=[]\n",
        "path='/content/drive/MyDrive/Projects/NLP/LLM_Project/Cleaned_data'\n",
        "for file in os.listdir(path):\n",
        "  file_text=os.path.join(path,file)\n",
        "  with open(file_text)as f:\n",
        "    data = json.load(f)\n",
        "    files.append(data)"
      ],
      "metadata": {
        "id": "-Jl3D13qeiOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "AC7vvOn5eiQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(        \n",
        "    separator = \"\\n\\n\",\n",
        "    chunk_size = 1600,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")"
      ],
      "metadata": {
        "id": "UXto5MJqeiTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "metadatas = []\n",
        "for doc in files:\n",
        "    text = doc[\"Content\"]\n",
        "    source = doc[\"Source\"]\n",
        "    splits = text_splitter.split_text(text)\n",
        "    for splited_text in splits:\n",
        "        docs.append(splited_text)\n",
        "        metadatas.append({\"source\":source})"
      ],
      "metadata": {
        "id": "GaHak5jEeiVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "id": "kZEV3MvYez52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(metadatas)"
      ],
      "metadata": {
        "id": "6QLsPMRYez8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "2thDWlXrez_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadatas[:10]"
      ],
      "metadata": {
        "id": "vOpOoj1reiZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  embeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "mgzarM6_fAqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectore stores\n",
        "store = FAISS.from_texts(docs,embeddings, metadatas=metadatas)\n",
        "faiss.write_index(store.index, \"docs.index\")\n",
        "store.index = None\n",
        "with open(\"vectors_stores.pkl\", \"wb\") as f:\n",
        "    pickle.dump(store, f)\n",
        "    "
      ],
      "metadata": {
        "id": "_0eztLS2fAwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.read_index(\"docs.index\")\n",
        "with open(\"vectors_stores.pkl\", \"rb\") as f:\n",
        "    store = pickle.load(f)\n",
        "store.index = index"
      ],
      "metadata": {
        "id": "IWSmcNKFvQi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(store)"
      ],
      "metadata": {
        "id": "IfL2-lgvsfxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"You are a SecurityGPT bot assistant by cyber security ltd that provides information on the cyber security issues. \n",
        "Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\").\n",
        "ALWAYS return a \"SOURCES\" part in your answer.\n",
        "\n",
        "\n",
        "Chat history\n",
        "{chat_history}\n",
        "\n",
        "QUESTION: What is the Sliver backdoor?\n",
        "=========\n",
        "Content: The ASEC analysis team identified the Sliver backdoor being deployed through vulnerability exploitation on a remote-control program, named Sunlogin. Since 2022, researchers have spotted several targeted attacks against the vulnerable process.\n",
        "Source: http://cyware.com/news/hackers-abuse-rce-vulnerability-to-deploy-sliver-backdoor-a76b3517\n",
        "\n",
        "Content: About Sliver\n",
        "\n",
        "Sliver, a former alternative to Cobalt Strike, is now a sought-after C2 framework for threat actors.\n",
        "\n",
        "As a cross-platform, open-source adversary simulation tool, it offers core features such as dynamic code generation and obfuscation, among others.\n",
        "It provides secure C2 communication over mTLS, HTTP(S), WireGuard, COFF/BOF in-memory loader, and others.\n",
        "The framework contains an extension package manager (armory) that allows easy installation (automatic compilation) of various third-party tools.\n",
        "Source: http://cyware.com/news/hackers-abuse-rce-vulnerability-to-deploy-sliver-backdoor-a76b3517\n",
        "=========\n",
        "FINAL ANSWER: The silver backdoor is a  open-source adversary simulation tool that offers core features such as dynamic code generation, obfuscation etc.\n",
        "It provides secure C2 communication over mTLS, HTTP(S), WireGuard, COFF/BOF in-memory loader, and others.\n",
        "The framework contains an extension package manager (armory) that allows easy installation (automatic compilation) of various third-party tools.\n",
        "Source: http://cyware.com/news/hackers-abuse-rce-vulnerability-to-deploy-sliver-backdoor-a76b3517\n",
        "\n",
        "\n",
        "QUESTION: {question}\n",
        "=========\n",
        "{summaries}\n",
        "=========\n",
        "FINAL ANSWER:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "d6B6-MEnfAzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_prompt = PromptTemplate(input_variables=[\"chat_history\", \"summaries\", \"question\"], template=template)\n"
      ],
      "metadata": {
        "id": "1f3MF8A_fTEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key='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'"
      ],
      "metadata": {
        "id": "UDA3zbxNfTGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY']=api_key"
      ],
      "metadata": {
        "id": "TPdQM2x4fTKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\",output_key=\"answer\")"
      ],
      "metadata": {
        "id": "86LRZxIxfe-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = VectorDBQAWithSourcesChain.from_llm(llm = OpenAI(model_name=\"text-davinci-003\", temperature=0), vectorstore=store, combine_prompt=c_prompt,memory=memory)\n",
        "# fetch the answer"
      ],
      "metadata": {
        "id": "6CHoBxFoffB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain({\"question\": \"How to import CNN Layer?\"})\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "id": "ROOflo2opsgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain({\"question\": \"How to use CNN Layer\"})\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "id": "xpDGxO71psi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xpz7xeQSpsmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}